# Lab 02 - Create a Kafka Producer

## Kafka Producer API

Let's write a Kafka producer using Kakfa's java API.

See the project `producer`. This project contains the code skeleton, it only needs to be completed.

The project contains:
* A class, [com.zenika.lab.HelloKafkaProducer](../producer/src/main/java/com/zenika/lab/HelloKafkaProducer.java), that you need to complete.
* A [build.gradle](../producer/build.gradle) file that contains the dependencies.
* A [property file](../producer/src/main/resources/application.properties).

Note that the project has already been set up to use `slf4j` - that is a prerequisite for the java Kafka library.

### Adding the Kafka clients library

First, let's add the `kafka-clients` library to the classpath. Add this dependency to your `build.gradle` file:

```groovy
implementation 'org.apache.kafka:kafka-clients:3.2.0'
```
Note that the version corresponds to the Kafka version.

If you are intelliJ, don't forget to reload your gradle environment.

### Adding the Kafka properties

Useful note: the message we will produce will have a `String` key and a `String` value. So we will use the
[StringSerializer](https://kafka.apache.org/32/javadoc/org/apache/kafka/common/serialization/StringSerializer.html).

Using Kafka means setting a lot of properties.
See the [documentation](https://kafka.apache.org/documentation.html) to have a description of each property.

Add the relevant properties to the `application.properties` file:
* `bootstrap.servers` to set the address of your Kafka cluster
* `key.serializer` full classpath to specify which serializer you use for the key...
* `value.serializer` ... and the value
* `acks` to all
* `enable.idempotence` to all
* `retries` to it's max value (2147483647)
* `batch.size` and `linger.ms` to set up batching
* `compression.type` to add compression (`snappy` is fine here)

See [producer-completed](../producer-completed) if you are struggling to find the proper values.

### Create the Kafka producer

First, to use Kafka, you need to declare a `KafkaProducer`. This producer is thread-safe, and auto-closable.
It takes some properties as a parameter.
It is typed for the key, and the value. For this lab, you will use String for both.
```java
try(KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties)) {
  
}
```

### Send the messages

The goal is to send 100 messages. Each message will have the same key, `hello-world`, and a random value generated by a
call to the `produceRandomNumber()` helper method.

You'll send 100 messages, so first let's write a `for` loop. Then to send your messages, you'll need to do to things:
* Create a `ProducerRecord<String, String>`
* Call the `send()` method of the `KafkaProducer`.

The `ProducerRecord` will contain information about the message you are trying to send: the topic, the key, and the value
```java
ProducerRecord<String, String> record = new ProducerRecord<>(
  "topic", "key", "value"
);
```
Replace with the appropriate key and value.

Then, to send the message:
```java
kafkaProducer.send(record);
```
Note that when the `send` method is called, the message is not yet sent to Kafka. In practice, the message is added to an
in-memory buffer. The message will be sent alongside other messages to the broker once the batch of messages it belongs
to is ready (remember `batch.size` and `linger.ms` ?).

Calling `send()` is not enough to know if the message has been properly sent. Luckily, the Kafka library provides two
ways of knowing if the message has been sent to Kafka. If you provide no additional argument than the record, then the
send method returns a `Future<RecordMetadata>`. Since it's a java future, you can force waiting for the cluster to repond
by using it's `get` method.

However, a better way exist. You can supply a lambda as the second argument of the `send()` method. This lambda must be a
`Callback` and implement a single method, `void onCompletion(RecordMetadata metadata, Exception exception)`.
If the exception is not `null`, this means there was an error sending the record to Kafka that your need to process in
your applicative code. If the exception is `null`, you are certain the record was sent successfully and you can use the
`RecordMetadata`.

For example, you could use it like this:
```java
kafkaProducer.send(record, (metadata, exception) -> {
  if (exception != null) {
    LOG.error("Error while sending record {} to Kafka: {}", record.key(), exception);
  } else {
    LOG.info("Record {} - {} sent to Kafka", record.key(), record.value());
  }
});
```
